{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.linalg import svd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from PyEMD import EMD  # pipenv install EMD-signal\n",
    "from ewtpy import EWT1D  # pipenv install ewtpy\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from fbm import FBM  # pip install fbm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"x.csv\", delimiter=\",\")\n",
    "Y = pd.read_csv(\"y.csv\", delimiter=\",\", dtype=np.float64)\n",
    "\n",
    "print(f\"Data read as: X -- {X.shape}, Y -- {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd25221",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i, c in enumerate(X.columns):\n",
    "    plt.subplot(len(X.columns), 1, i+1)\n",
    "    plt.plot(X[c])\n",
    "    plt.ylabel(c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed032ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in X.columns:\n",
    "    print(f\"Series {c} has {sum(X[c].isna())} NaN-values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bdeb5f",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34906976",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=Y.to_numpy(), cmap='viridis', edgecolor='k', s=50)\n",
    "plt.title('PCA of X')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Y')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea6891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def dtc_linear_regression(X, Y, test_size=.2, random_state=42, log=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    # Train a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    if log: print(f\"Mean Squared Error: {mse}\")\n",
    "    if log: print(f\"R^2 Score: {r2}\")\n",
    "    # Plot the predictions against the true values\n",
    "    if log:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "        plt.xlabel('True Values')\n",
    "        plt.ylabel('Predictions')\n",
    "        plt.title('True vs Predicted Values')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        # plt.plot(Y)\n",
    "        plt.plot((Y - model.predict(X))/(Y))\n",
    "    \n",
    "    return mse, r2\n",
    "\n",
    "dtc_linear_regression(X, Y, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f912098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "test_seeds = np.random.randint(1, high=4294967295, size=1000)\n",
    "res = [dtc_linear_regression(X, Y, test_size=0.99, random_state=r) for r in test_seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cbed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses, r2s = zip(*res)\n",
    "print(f\"Mean mse: {np.mean(mses):.3f}, mean r2: {np.mean(r2s):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.sort(r2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sizes = [.99, .95, .90, .75, .50, .25, .10, .05, .01]\n",
    "plt.figure(figsize=(12,12))\n",
    "\n",
    "for ts in test_sizes:\n",
    "    np.random.seed(42)\n",
    "    test_seeds = np.random.randint(1, high=4294967295, size=1000)\n",
    "    res = [dtc_linear_regression(X, Y, test_size=ts, random_state=r) for r in test_seeds]\n",
    "    mses, r2s = zip(*res)\n",
    "    # print(f\"Mean mse: {np.mean(mses):.3f}, mean r2: {np.mean(r2s):.3f}\")\n",
    "    plt.subplot(1, 2, 1); plt.plot(np.sort(mses), label=f\"{ts}\")\n",
    "    plt.subplot(1, 2, 2); plt.plot(np.sort(r2s), label=f\"{ts}\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d4ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.2, random_state=42)\n",
    "# Train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "# Plot the predictions against the true values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d22b94",
   "metadata": {},
   "source": [
    "## EMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emd = EMD()\n",
    "imfs_emd = emd(Y.DTC.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27bc67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(imfs_emd.shape[0]+1, 1, 1); plt.plot(Y.DTC)\n",
    "\n",
    "for i in range(imfs_emd.shape[0]):\n",
    "    plt.subplot(imfs_emd.shape[0]+1, 1, i+2)\n",
    "    plt.plot(imfs_emd[i, :])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512aa41",
   "metadata": {},
   "source": [
    "## EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f784dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ewt_c = 5\n",
    "ewt_output = EWT1D(Y.DTC, N = n_ewt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589cb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(n_ewt_c+1, 1, 1)\n",
    "plt.plot(Y.DTC)\n",
    "\n",
    "for i in range(n_ewt_c):\n",
    "    plt.subplot(n_ewt_c + 1, 1, i+2)\n",
    "    plt.plot(ewt_output[0][:, i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432aed0",
   "metadata": {},
   "source": [
    "## DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071b6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrended_fluctuation_analysis(signal, scales, order=1):\n",
    "    N = len(signal)\n",
    "    Y = np.cumsum(signal - np.mean(signal))\n",
    "    F = []\n",
    "\n",
    "    for s in scales:\n",
    "        n_segments = N // s\n",
    "        local_rms = []\n",
    "\n",
    "        for i in range(n_segments):\n",
    "            segment = Y[i*s:(i+1)*s]\n",
    "            x = np.arange(s)\n",
    "            coeffs = np.polyfit(x, segment, order)\n",
    "            trend = np.polyval(coeffs, x)\n",
    "            rms = np.sqrt(np.mean((segment - trend)**2))\n",
    "            local_rms.append(rms)\n",
    "\n",
    "        F.append(np.sqrt(np.mean(np.square(local_rms))))\n",
    "\n",
    "    return np.array(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7833767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(Y)\n",
    "scales = np.unique(np.logspace(1.1, np.log10(N/4), num=30, dtype=int))\n",
    "\n",
    "dfa_dtc = detrended_fluctuation_analysis(Y.DTC.to_numpy(), scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154647fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scales = np.log(scales)\n",
    "log_F = np.log(dfa_dtc)\n",
    "\n",
    "alpha, intercept = np.polyfit(log_scales, log_F, 1)\n",
    "\n",
    "plt.plot(log_scales, log_F, 'o', label=\"DFA\")\n",
    "plt.plot(log_scales, np.polyval([alpha, intercept], log_scales), linestyle=\"--\", label=f\"Fit: alpha = {alpha:.3f}\")\n",
    "# plt.plot(log_scales, alpha*log_scales+intercept)\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d7b2ec",
   "metadata": {},
   "source": [
    "## ARIMA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ba3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_diffed = np.diff(Y.DTC)\n",
    "plt.plot(dtc_diffed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e1fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_diffed_dtc = detrended_fluctuation_analysis(dtc_diffed, scales)\n",
    "dtc_diffed_log_F = np.log(dfa_diffed_dtc)\n",
    "dtc_diffed_poly = np.polyfit(log_scales, dtc_diffed_log_F, 1)\n",
    "\n",
    "plt.plot(log_scales, dtc_diffed_log_F, 'o', label=\"DFA\")\n",
    "plt.plot(log_scales, np.polyval(dtc_diffed_poly, log_scales), label=f\"Fit: alpha = {dtc_diffed_poly[0]:.3f}\")\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff5629",
   "metadata": {},
   "source": [
    "## Power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, dct, idct, ifft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245efec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21333b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = fft(Y.DTC)\n",
    "# a = dct(Y.DTC)\n",
    "a = dct(dtc_diffed)\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928882d8",
   "metadata": {},
   "source": [
    "## PLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c6655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def dtc_regession_monte_carlo(X, Y, test_size=0.2, random_state=42, log=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    model = PLSRegression(n_components=2, scale=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    # Evaluate the model\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    if log: print(f\"Mean Squared Error: {mse}\")\n",
    "    if log: print(f\"R^2 Score: {r2}\")\n",
    "    # Plot the predictions against the true values\n",
    "    if log:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "        plt.xlabel('True Values')\n",
    "        plt.ylabel('Predictions')\n",
    "        plt.title('True vs Predicted Values')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(Y)\n",
    "        plt.plot(model.predict(X))\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot((Y - model.predict(X))/(Y))\n",
    "        plt.show()\n",
    "    \n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535deb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(42)\n",
    "test_seeds = np.random.randint(1, high=4294967295, size=1000)\n",
    "res = [dtc_regession_monte_carlo(X, Y, test_size=.2, random_state=r) for r in test_seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c284a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses, r2s = zip(*res) \n",
    "print(f\"Mean mse: {np.mean(mses):.3f}, mean r2: {np.mean(r2s):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc98d8f8",
   "metadata": {},
   "source": [
    "## RPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a992ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpca import RobustPCA\n",
    "\n",
    "rpca = RobustPCA(0.1)\n",
    "\n",
    "L, S = rpca.fit(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e29cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.axhline(40)\n",
    "X.GR.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547b378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.subplot(len(X.columns)+1, 1, 1)\n",
    "plt.plot(Y)\n",
    "for i, c in enumerate(X.columns):\n",
    "    plt.subplot(len(X.columns)+1, 1, i+2)\n",
    "    plt.plot(S[:, i])\n",
    "    plt.ylabel(c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8755e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_linear_regression(L, Y, log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ham-nl-vQ_QP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
